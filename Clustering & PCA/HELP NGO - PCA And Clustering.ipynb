{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>HELP International NGO</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "HELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. <br>\n",
    "Key problem statements are: \n",
    "**<ul>\n",
    "    <li>How to use newly received $10 million funding strategically and effectively</li>\n",
    "    <li>Categorise the countries using socio-economic and health factors.</li>\n",
    "    <li>Choose appropriate countries that are in the direst need of aid.</li>\n",
    "</ul>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Perform EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_csv('data-dictionary.csv', index_col='Column Name')\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf = pd.read_csv('Country-data.csv')\n",
    "countryDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(countryDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[['country']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we have 167 rows containing 167 unique countries. <br>\n",
    "So, no duplicate data rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "numericCol = countryDf.columns.drop('country')\n",
    "index = 1\n",
    "for col in numericCol:\n",
    "    plt.subplot(3,3,index)\n",
    "    sns.boxplot(data=countryDf, y=col)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "numericCol = countryDf.columns.drop('country')\n",
    "index = 1\n",
    "for col in numericCol:\n",
    "    plt.subplot(3,3,index)\n",
    "    sns.distplot(countryDf[col])\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysing Outlier based on different features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf['child_mort'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf['life_expec'] < 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High Child_mort** rate &  **low life_expec** rate is big concern.<BR>\n",
    "If we check other features it shows under developed countries (Where GDP capita is low as well and heath expenditure as compare to GDP is low also low income per person) facing such kind of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf['exports'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf['income'] > 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf[countryDf['gdpp'] > 40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countryDf[countryDf['inflation'] > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few outliners in Data, but data set is very small with 167 Observation.<BR>\n",
    "So will keep all data as is and perform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check correlation with heatmap\n",
    "corr = countryDf.corr()\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(corr, cmap='RdBu', annot=True,  mask=mask, center=0, linewidths= 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few features are highly  corelated.\n",
    "Will can drop few of the feature like **Total_Fer, Income, Exports** <BR>\n",
    "But will keep all the features as is and use **PCA** to Solve **Multicollinearity** factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few of the features are corelated with each other, instead of checking & removing features manually will implement PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Implementation\n",
    "Before performing PCA will first scale data on Standard Scalar as income & gdpp feature have wide spread as compare to other features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDf = countryDf.drop(labels='country', axis=1)\n",
    "sc = StandardScaler()\n",
    "scalledData = sc.fit_transform(trainDf)\n",
    "trainDf_scalled = pd.DataFrame(data=scalledData, columns=trainDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver='randomized', random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(trainDf_scalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(trainDf_scalled.columns, name='Feature')\n",
    "pcaDF = pd.DataFrame(data=pca.components_.T, columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9'])\n",
    "pcaDF = pd.concat([features, pcaDF], axis=1)\n",
    "pcaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative variance explained by PCA component\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot scree plot to check Cumulative Variance Explaining by PCA component\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per above scree plot **5** PCA component explains **94.5%** of variance, if we take **6** components will get hardly **1.5%** of gain in variance explained by component.<BR>\n",
    "So will take **5** component and build clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "final_pca = IncrementalPCA(n_components=5)\n",
    "trainDf_pca = final_pca.fit_transform(trainDf_scalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check correlation with heatmap\n",
    "corr = np.corrcoef(trainDf_pca.transpose()).round(2)\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "sns.heatmap(corr, cmap='RdBu', annot=True,  mask=mask, center=0, linewidths= 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no Correlation between any 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.Series(trainDf_scalled.columns, name='Feature')\n",
    "final_pcaDF = pd.DataFrame(data=final_pca.components_.T, columns=['PC1','PC2','PC3','PC4','PC5'])\n",
    "final_pcaDF = pd.concat([features, final_pcaDF], axis=1)\n",
    "final_pcaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf_pca = pd.DataFrame(data=trainDf_pca)\n",
    "trainDf_pca.columns = ['PC1','PC2','PC3','PC4','PC5']\n",
    "trainDf_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building : Using Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First analyze  **Hopkins Statistic** to check data tendency/pattern fits for clustering or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from math import isnan\n",
    " \n",
    "def HopkinsStats(data):\n",
    "    d = data.shape[1]\n",
    "    n = len(data) # rows\n",
    "    m = int(0.1 * n)\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(data.values)\n",
    "    \n",
    "    rand_data = sample(range(0, n, 1), m)\n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(0, m):\n",
    "        u_dist, _ = nbrs.kneighbors(np.random.uniform(np.amin(data,axis=0),np.amax(data,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(data.iloc[rand_data[j]].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    "\n",
    "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if isnan(H):\n",
    "        H = 0\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HopkinsStats(trainDf_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Hopkins Statistics have value between **0.7 - 0.99** than data is good for clustering. <BR>\n",
    "Our Hopkins Stats value is ** > 0.7** which show good tendency of clustering. <BR><BR>\n",
    "Will implement **K-Mean & Hierarchical Clustering** algorithm on data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Mean Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K-Mean algorithm we have to first find of number on Cluster required of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sum of Squared Error** method to find number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "for k in range(2,15):\n",
    "    kMean_model = KMeans(n_clusters=k, random_state= 0, max_iter=50)\n",
    "    kMean_model.fit(trainDf_pca)\n",
    "    sse.append([k,kMean_model.inertia_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(sse)[0], pd.DataFrame(sse)[1]);\n",
    "plt.ylabel(\"Sum Of Squared Error\")\n",
    "plt.xlabel(\"No Of Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elbow Method** to derive number of clusters.<BR>\n",
    "Will use **Silhouette Analysis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "ss = []\n",
    "for k in range(2, 15):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(trainDf_pca)\n",
    "    ss.append([k, silhouette_score(trainDf_pca, kmeans.labels_)])\n",
    "\n",
    "plt.plot(pd.DataFrame(ss)[0], pd.DataFrame(ss)[1], '-gD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sum of Squared Error** method shows more cluster are better, three is significant drop in SSE till approx. 8 cluster. But having 8 clusters are not good approach. <BR><BR>\n",
    "**Elbow Method: Using Silhouette Analysis** technique shows 5 clusters are good for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeans_Clust5 = KMeans(n_clusters=5, max_iter=50, random_state=0)\n",
    "kMeans_Clust5.fit(trainDf_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kMeans_Clust5.labels_.shape)\n",
    "kMeans_Clust5.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean_DF = pd.concat([pd.Series(kMeans_Clust5.labels_, name=\"ClusterId\"), countryDf, trainDf_pca], axis=1)\n",
    "kMean_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean_DF['ClusterId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpMean = kMean_DF.groupby(by=['ClusterId']).mean()\n",
    "grpMean = grpMean.reset_index()\n",
    "grpMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(data=kMean_DF, x='PC1', y='PC2', hue='ClusterId', style='ClusterId', legend=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All clusters have clear segregation except Cluster 4. <BR>\n",
    "PC1 & PC2 data points segregate data properly, will choose some feature variable to analyze clusters.<BR>\n",
    "Will choose features based on Linear Combination value of features in PC1 & PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pcaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.scatterplot(data=kMean_DF, x='gdpp', y='exports', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,2)\n",
    "sns.scatterplot(data=kMean_DF, x='gdpp', y='life_expec', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,3)\n",
    "sns.scatterplot(data=kMean_DF, x='gdpp', y='child_mort', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,4)\n",
    "sns.scatterplot(data=kMean_DF, x='gdpp', y='income', hue='ClusterId', style='ClusterId', legend=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(3,3,1)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='child_mort')\n",
    "plt.subplot(3,3,2)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='exports')\n",
    "plt.subplot(3,3,3)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='health')\n",
    "plt.subplot(3,3,4)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='imports')\n",
    "plt.subplot(3,3,5)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='income')\n",
    "plt.subplot(3,3,6)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='inflation')\n",
    "plt.subplot(3,3,7)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='life_expec')\n",
    "plt.subplot(3,3,8)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='total_fer')\n",
    "plt.subplot(3,3,9)\n",
    "sns.barplot(data=grpMean, x='ClusterId', y='gdpp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key features of Developed Countries are: High Income, High GDPP, Low Inflation, High Life Expectancy, High Health Spending, Low Child Mortality Rate, etc.  <BR>\n",
    "In contrast Under Developed Countries are having: Low Income, Low GDPP, High Inflation, High Child Mortality rate, Low Life Expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above graph we can say that Countries in **Cluster Id - 0** are under developed countries. <BR>\n",
    "Countries in **Cluster Id -  4 ** doing better than **Cluster Id - 0**<BR>\n",
    "Looks like Countries in **Cluster Id - 1 & 2 ** and developed countries.<BR><BR>\n",
    "\n",
    "Will verify each cluster and for our analysis will stick to **Cluster 0 & 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean_DF[(kMean_DF['ClusterId'] == 0)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under Developed Countries\n",
    "kMean_DF[(kMean_DF['ClusterId'] == 0)].sort_values(by=['child_mort'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under Developed Countries\n",
    "kMean_DF[(kMean_DF['ClusterId'] == 0)].sort_values(by=['life_expec']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under Developed Countries\n",
    "kMean_DF[(kMean_DF['ClusterId'] == 0)].sort_values(by=['inflation'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean_DF[(kMean_DF['ClusterId'] == 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above analysis and key features like **Chile Mortality, GDPP, Inflation, Life Expectancy** we can Cheery Pick countries which are in direst need of aid<BR>\n",
    "<ul>\n",
    "    <li>**Haiti** : Very high Child Mortality rate **208**& very low life expectancy **32**</li>\n",
    "    <li>**Sierra Leone** : Same as Haiti, this country also have very high Child Mortality rate & low life expectancy, GDPP of this country is very low **399** and Inflation is very high **17.20** (more than 75% from that Cluster) </li>\n",
    "    <li>**Chad & Central African Republic** : Both the countries showing same trend High Child Mortality with Low Life Expectancy as well as Low GDPP. **Chad** have very high Total fertility ration </li>\n",
    "    <li>**Nigeria** : This country from cluster 4 have very high Inflation rate **104** and high child mortality **130**. </li>\n",
    "    <li>**Mali** : Here Total Fertility to each women is very high **6.55** which can impact high Child Mortality **137**. </li>\n",
    "    <li>**Niger** : With very high Total fertility rate and low GDPP this country also facing High Child Mortality problem.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "mergings = linkage(trainDf_pca, method = \"complete\", metric='euclidean')\n",
    "dendrogram(mergings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will use same cluster size as K-Mean Algo\n",
    "clusterCut = pd.Series(cut_tree(mergings, n_clusters = 5).reshape(-1,), name=\"ClusterId\")\n",
    "hierar_DF = pd.concat([clusterCut, countryDf, trainDf_pca], axis=1)\n",
    "hierar_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF['ClusterId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpHierarClust = hierar_DF.groupby(by=['ClusterId']).mean()\n",
    "grpHierarClust = grpHierarClust.reset_index()\n",
    "grpHierarClust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like **Cluster Id - 4 ** is group of under developed countries with High Chile Mortality, Very High Inflation Rate, Low GDPP, Low Heath Expenditure. But there is only 1 country assigned in that group. <BR>\n",
    "**Cluster Id - 0** is another group shows similar trend and 38 countries assigned to that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(data=hierar_DF, x='PC1', y='PC2', hue='ClusterId', style='ClusterId', legend=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.scatterplot(data=hierar_DF, x='gdpp', y='exports', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,2)\n",
    "sns.scatterplot(data=hierar_DF, x='gdpp', y='life_expec', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,3)\n",
    "sns.scatterplot(data=hierar_DF, x='gdpp', y='child_mort', hue='ClusterId', style='ClusterId', legend=\"full\")\n",
    "plt.subplot(2,2,4)\n",
    "sns.scatterplot(data=hierar_DF, x='gdpp', y='income', hue='ClusterId', style='ClusterId', legend=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precise segregation of data in Hierarchical Clustering than KMean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,10))\n",
    "plt.subplot(3,3,1)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='child_mort')\n",
    "plt.subplot(3,3,2)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='exports')\n",
    "plt.subplot(3,3,3)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='health')\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='imports')\n",
    "plt.subplot(3,3,5)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='income')\n",
    "plt.subplot(3,3,6)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='inflation')\n",
    "plt.subplot(3,3,7)\n",
    "\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='life_expec')\n",
    "plt.subplot(3,3,8)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='total_fer')\n",
    "plt.subplot(3,3,9)\n",
    "sns.barplot(data=grpHierarClust, x='ClusterId', y='gdpp')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF[(hierar_DF['ClusterId'] == 0)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF[(hierar_DF['ClusterId'] == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF[(hierar_DF['ClusterId'] == 0)].sort_values(by=['child_mort'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF[(hierar_DF['ClusterId'] == 0)].sort_values(by=['life_expec']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierar_DF[(hierar_DF['ClusterId'] == 0)].sort_values(by=['gdpp']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both the clustering algorithm similar kind of clusters generated.<BR>\n",
    "Both methods shows **Cluster 0 & Cluster 4** contains under developed countries and faces similar kind of problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finalized below mentioned list of countries which are in direst need of aid:\n",
    "<ol>\n",
    "    <li>**Haiti**</li>\n",
    "    <li>**Sierra Leone**</li>\n",
    "    <li>**Chad**</li>\n",
    "    <li>**Central African Republic**</li>\n",
    "    <li>**Nigeria**</li>\n",
    "    <li>**Mali**</li>\n",
    "    <li>**Niger**</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kMean_DF.to_csv('kMean_Clustering.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
